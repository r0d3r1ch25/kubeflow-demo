# Kubeflow Pipelines on k3d - Lightweight Local Setup

A minimal, production-ready Kubeflow Pipelines deployment running on k3d for local development and experimentation. Perfect for ML engineers who want to explore Kubeflow without the complexity of a full cluster setup.

## ğŸ¯ What You Get

- **Kubeflow Pipelines** - Complete ML workflow orchestration
- **Jupyter Notebooks** - Interactive development environment  
- **MinIO** - S3-compatible artifact storage
- **MySQL** - Pipeline metadata storage
- **Argo Workflows** - Robust pipeline execution engine

All running locally with minimal resource usage, tested on Apple Silicon (M-series) Macs.

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install required tools (macOS)
brew install make kubectl k3d
```

### One-Command Deploy

```bash
make cluster-up
```

That's it! The command will:
1. Create a k3d cluster with proper port forwarding
2. Deploy all Kubeflow components
3. Wait for everything to be ready
4. Show you the access URLs

### Access Your Services

Once deployed, access these URLs in your browser (using NodePort services):

- **ğŸ”¬ Kubeflow Pipelines UI**: http://localhost:31380
- **ğŸ“Š MinIO Console**: http://localhost:31390 (user: `minio`, pass: `minio123`)
- **ğŸ““ Jupyter Notebook**: http://localhost:31400 (no password required)

> **Note**: Services are exposed via NodePort on your local machine. The k3d cluster automatically forwards these ports to localhost.

## ğŸ—ï¸ Architecture

This setup provides a complete ML pipeline platform with:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Jupyter       â”‚    â”‚  Kubeflow       â”‚    â”‚     MinIO       â”‚
â”‚   Notebooks     â”‚â—„â”€â”€â–ºâ”‚   Pipelines     â”‚â—„â”€â”€â–ºâ”‚   Storage       â”‚
â”‚   :31400        â”‚    â”‚    :31380       â”‚    â”‚   :31390        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     MySQL       â”‚
                    â”‚   Metadata      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **MySQL 8.0** - Pipeline metadata and experiment tracking
- **MinIO** - Artifact storage (models, datasets, outputs)
- **Argo Workflows** - Pipeline execution engine
- **ML Pipeline API 2.0** - REST API with v2beta1 support
- **ML Pipeline UI 2.0** - Web interface for pipeline visualization
- **Visualization Server** - Pipeline step visualizations
- **ML Metadata (MLMD)** - Execution tracking and lineage
- **Metadata Envoy** - Proxy for metadata services
- **Persistence Agent** - Workflow completion handling
- **Scheduled Workflow** - Recurring pipeline execution
- **Jupyter Notebook** - Development and experimentation

## ğŸ“‹ Available Commands

```bash
# Deploy everything
make cluster-up

# Check component status
make status

# Deploy to existing cluster
make deploy

# Remove components (keep cluster)
make undeploy

# Delete entire cluster
make cluster-down

# Get Jupyter token (if needed)
make token
```

## ğŸ”§ Development Workflow

1. **Develop** in Jupyter Notebooks at http://localhost:31400
2. **Create** ML pipelines using the Kubeflow Pipelines SDK
3. **Upload** and run pipelines via the UI at http://localhost:31380
4. **Monitor** execution and view artifacts
5. **Iterate** and improve your ML workflows

## ğŸ“ Project Structure

```
k8s/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ namespace.yaml      # Kubeflow namespace
â”‚   â””â”€â”€ rbac.yaml          # Service accounts and permissions
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ minio.yaml         # S3-compatible object storage
â”‚   â””â”€â”€ mysql.yaml         # Pipeline metadata database
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ argo-workflow.yaml           # Workflow execution engine
â”‚   â”œâ”€â”€ scheduledworkflow-crd.yaml   # Custom resource definitions
â”‚   â”œâ”€â”€ ml-pipeline.yaml             # Pipeline API server (v2.0)
â”‚   â”œâ”€â”€ ml-pipeline-ui.yaml          # Web interface (v2.0)
â”‚   â”œâ”€â”€ ml-pipeline-visualizationserver.yaml  # Visualization service
â”‚   â”œâ”€â”€ metadata-envoy.yaml          # ML Metadata proxy
â”‚   â”œâ”€â”€ metadata-grpc.yaml           # ML Metadata GRPC server
â”‚   â”œâ”€â”€ ml-pipeline-persistenceagent.yaml     # Workflow completion
â”‚   â””â”€â”€ ml-pipeline-scheduledworkflow.yaml    # Recurring pipelines
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ jupyter.yaml       # Jupyter notebook server
â””â”€â”€ kustomization.yaml     # Kustomize configuration
```

## ğŸ’¡ Use Cases

- **ML Experimentation** - Rapid prototyping of ML workflows
- **Pipeline Development** - Build and test Kubeflow pipelines locally
- **Education** - Learn Kubeflow concepts without cloud complexity
- **CI/CD Testing** - Validate pipelines before production deployment
- **Resource Optimization** - Test pipeline resource requirements

## ğŸ–¥ï¸ System Requirements

**Tested Environment:**
- macOS (Apple Silicon M-series recommended)
- 8GB+ RAM available for Docker
- 10GB+ free disk space

**Resource Usage:**
- ~2GB RAM for all components
- ~5GB disk space for images and data
- Minimal CPU usage when idle

## ğŸ” Troubleshooting

### Check Component Status
```bash
kubectl get pods -n kubeflow
```

### View Logs
```bash
# Pipeline API logs
kubectl logs -n kubeflow -l app=ml-pipeline

# UI logs  
kubectl logs -n kubeflow -l app=ml-pipeline-ui

# All component logs
kubectl logs -n kubeflow --all-containers=true
```

### Reset Everything
```bash
make cluster-down
make cluster-up
```

## ğŸš¦ What's Different

Unlike heavy Kubeflow distributions, this setup:

- âœ… **Lightweight** - Only essential components
- âœ… **Fast startup** - Ready in minutes, not hours
- âœ… **Local-first** - No cloud dependencies
- âœ… **Apple Silicon** - Optimized for M-series Macs
- âœ… **Modular** - Easy to understand and modify
- âœ… **Production patterns** - Real MySQL, proper RBAC
- âœ… **No Istio** - Simplified networking with NodePort access
- âœ… **Init containers** - Proper startup dependencies

## ğŸ¤ Usage

Feel free to fork this repository or clone it for your own ML experiments.
This setup is designed to be easily customizable for different use cases.

## ğŸ“„ License

MIT License - feel free to use this for your projects.

---

*This setup gets you from zero to running ML pipelines in under 10 minutes. Perfect for exploring Kubeflow capabilities without the operational overhead.*